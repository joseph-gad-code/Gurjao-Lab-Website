# This workflow automatically scrapes a Google Scholar profile,
# merges the data with manual overrides, and commits the result to the repository.

name: "Update publications (Google Scholar)"

on:
  # Allows manual triggering of the workflow from the Actions tab.
  workflow_dispatch:
  # Runs on a schedule.
  schedule:
    # Runs every Monday at 03:00 UTC.
    - cron: "0 3 * * 1"

# Sets write permissions for the contents of the repository,
# allowing the action to commit changes.
permissions:
  contents: write

jobs:
  build-publications:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install jq, yq, and pup
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          # Install yq
          curl -fsSL https://github.com/mikefarah/yq/releases/download/v4.44.2/yq_linux_amd64 -o yq
          sudo install -m 0755 yq /usr/local/bin/yq
          # Install pup for HTML parsing
          curl -fsSL https://github.com/ericchiang/pup/releases/download/v0.4.0/pup_v0.4.0_linux_amd64.zip -o pup.zip
          unzip pup.zip
          sudo install -m 0755 pup /usr/local/bin/pup
          yq --version
          jq --version
          pup --version

      - name: Create data directory
        run: mkdir -p _data

      - name: Scrape publications from Google Scholar
        env:
          # The full URL of the Google Scholar profile to scrape.
          SCHOLAR_URL: "https://scholar.google.com/citations?user=m3rLfS4AAAAJ&hl=en"
        run: |
          # Scrape the HTML page. A real user-agent is used to avoid being blocked.
          curl -sS -A "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36" "$SCHOLAR_URL" > _data/scholar.raw.html
          
          # Use pup to parse the HTML and extract publication data into a raw JSON format.
          # This selects each publication row and extracts the title, authors, journal, and year.
          cat _data/scholar.raw.html | pup '#gsc_a_b tr.gsc_a_tr json{}' | jq '
            [
              .[] | {
                "title": .children[0].children[0].text,
                "url": .children[0].children[0].href,
                "authors": .children[0].children[1].text,
                "journal": .children[0].children[2].text,
                "year": .children[2].children[0].text
              }
            ]
          ' > _data/scholar.raw.json

      - name: Normalize to site schema (JSON)
        run: |
          # This jq script transforms the raw scraped data into a clean, consistent format.
          # NOTE: Google Scholar does not provide DOIs on the main page, so this field is left empty.
          jq -r '
            map({
              title: .title,
              authors: .authors,
              year: (.year | tonumber? // null),
              journal: .journal,
              doi: "", # DOI is not available from the main scholar page
              url: ("https://scholar.google.com" + .url),
              selected_publication: false,
              image: ""
            })
          ' _data/scholar.raw.json > _data/publications.auto.json

      - name: Convert auto JSON→YAML (optional artifact)
        run: |
          yq -P '.' _data/publications.auto.json > _data/publications.auto.yml

      - name: Ensure manual overrides file exists
        run: |
          if [ ! -f _data/publications.manual.yml ]; then
            echo -e "# This file allows you to override or add publication details manually.\n# Entries are matched by DOI (which you must add here).\n# Example:\n# - doi: 10.1038/s41586-020-2649-2\n#   title: \"A different title for display\"\n#   selected_publication: true\n#   image: /assets/images/publications/example.png" > _data/publications.manual.yml
          fi

      - name: Convert manual YAML→JSON
        run: |
          yq -o=json '.' _data/publications.manual.yml > _data/publications.manual.json

      - name: Merge auto + manual (manual overrides win), sort by year desc
        run: |
          # This script merges the automated list with your manual overrides.
          # Since DOIs are missing from the scrape, the merge logic is updated to use title as a fallback key.
          jq -s '
            # Helper function to convert an array to a map keyed by DOI, or title if DOI is missing.
            def to_map:
              map(
                { key: (.doi | if . and . != "" then . else .title end), value: . }
                | select(.key != null)
                | { (.key): .value }
              ) | add // {};
            # Helper function to convert the map back to an array.
            def to_array(m): [ m | to_entries[] | .value ];

            . as $all
            | ($all[0] | to_map) as $auto
            | ($all[1] | to_map) as $manual
            | ($auto * $manual)      # Deep merge: manual values override auto values.
            | to_array(.)
            | sort_by(.year) | reverse # Sort publications by year, newest first.
          ' _data/publications.auto.json _data/publications.manual.json > _data/publications.json

      - name: Convert final JSON→YAML
        run: |
          yq -P '.' _data/publications.json > _data/publications.yml

      - name: Commit changes
        run: |
          # Check if any of the relevant files have changed.
          if git status --porcelain | grep -q "_data/publications"; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            # Add all generated and manual files to the commit.
            git add _data/*.yml _data/*.json _data/*.html
            git commit -m "chore: update publications from Google Scholar"
            git push
          else
            echo "No publication changes."
          fi

